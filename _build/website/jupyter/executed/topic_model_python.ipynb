{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='index-0'></a>\n",
    "\n",
    "<a id='topic-model-python'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling in Python\n",
    "\n",
    "This section illustrates how to do approximate topic modeling in Python. We will\n",
    "use a technique called [non-negative matrix factorization (NMF)](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization) that\n",
    "strongly resembles Latent Dirichlet Allocation (LDA) which we covered in the\n",
    "previous section, [Topic modeling with MALLET](topic_model_mallet.html#topic-model-mallet). <sup><a href=#fn-nmf id=fn-nmf-link>[1]</a></sup> Whereas LDA is\n",
    "a probabilistic model capable of expressing uncertainty about the placement of\n",
    "topics across texts and the assignment of words to topics, NMF is\n",
    "a deterministic algorithm which arrives at a single representation of the\n",
    "corpus. For this reason, NMF is often characterized as a machine learning\n",
    "algorithm. Like LDA, NMF arrives at its representation of a corpus in terms of\n",
    "something resembling “latent topics”.\n",
    "\n",
    ">**Note**\n",
    ">\n",
    ">The name “Non-negative matrix factorization” has the virtue of being\n",
    "transparent. A “non-negative matrix” is a matrix containing non-negative\n",
    "values (here zero or positive word frequencies). And\n",
    "factorization refers to the familiar kind of mathematical factorization.\n",
    "Just as a polynomial $ x^2 + 3x + 2 $ may be factored into a simple\n",
    "product $ (x+2)(x+1) $, so too may a matrix\n",
    "$ \\bigl(\\begin{smallmatrix} 6&2&4\\\\ 9&3&6 \\end{smallmatrix} \\bigr) $ be\n",
    "factored into the product of two smaller matrices\n",
    "$ \\bigl(\\begin{smallmatrix} 2\\\\ 3 \\end{smallmatrix} \\bigr)\n",
    "\\bigl(\\begin{smallmatrix} 3&2&1 \\end{smallmatrix} \\bigr) $.\n",
    "\n",
    "This section follows the procedures described in [Topic modeling with MALLET](topic_model_mallet.html#topic-model-mallet),\n",
    "making the substitution of NMF for LDA where appropriate.\n",
    "\n",
    "This section uses the novels by Brontë and Austen. These novels are divided into\n",
    "parts as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/austen-brontë-split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54a81d82a83a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mCORPUS_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'austen-brontë-split'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCORPUS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCORPUS_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/austen-brontë-split'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "CORPUS_PATH = os.path.join('data', 'austen-brontë-split')\n",
    "filenames = sorted([os.path.join(CORPUS_PATH, fn) for fn in os.listdir(CORPUS_PATH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4ff59eae8c96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# files are located in data/austen-brontë-split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filenames' is not defined"
     ]
    }
   ],
   "source": [
    "# files are located in data/austen-brontë-split\n",
    "len(filenames)\n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Non-negative matrix factorization\n",
    "\n",
    "As always we need to give Python access to our corpus. In this case we will work\n",
    "with our familiar document-term matrix.\n",
    "\n",
    "By analogy with LDA, we will use NMF to get a document-topic matrix (topics here\n",
    "will also be referred to as “components”) and a list of top words for each\n",
    "topic. We will make analogy clear by using the same variable names:\n",
    "`doctopic` and `topic_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "num_topics = 20\n",
    "num_top_words = 20\n",
    "\n",
    "clf = decomposition.NMF(n_components=num_topics, random_state=1)\n",
    "\n",
    "# this next step may take some time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide-output": false
   },
   "source": [
    "```python\n",
    "doctopic = clf.fit_transform(dtm)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NMF' object has no attribute 'components_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f8f67971eb69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print words associated with topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtopic_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mword_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_top_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtopic_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NMF' object has no attribute 'components_'"
     ]
    }
   ],
   "source": [
    "# print words associated with topics\n",
    "topic_words = []\n",
    "for topic in clf.components_:\n",
    "    word_idx = np.argsort(topic)[::-1][0:num_top_words]\n",
    "    topic_words.append([vocab[i] for i in word_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the analysis and visualization of NMF components similar to that of\n",
    "LDA’s topic proportions, we will scale the document-component matrix such that\n",
    "the component values associated with each document sum to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doctopic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e917c622b757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoctopic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoctopic\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoctopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'doctopic' is not defined"
     ]
    }
   ],
   "source": [
    "doctopic = doctopic / np.sum(doctopic, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will average those topic shares associated with the same novel together\n",
    "— just as we did with the topic shares from MALLET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-657117322ce2>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-657117322ce2>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    assert len(set(novel_names)) == 6\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "novel_names = []\n",
    "for fn in filenames:\n",
    "    basename = os.path.basename(fn)\n",
    "    # splitext splits the extension off, 'novel.txt' -> ('novel', '.txt')\n",
    "    name, ext = os.path.splitext(basename)\n",
    "    # remove trailing numbers identifying chunk\n",
    "    name = name.rstrip('0123456789')\n",
    "    novel_names.append(name)\n",
    "# turn this into an array so we can use NumPy functions\n",
    "novel_names = np.asarray(novel_names)\n",
    "\n",
    "@suppress\n",
    "assert len(set(novel_names)) == 6\n",
    "@supress\n",
    "doctopic_orig = doctopic.copy()\n",
    "\n",
    "# use method described in preprocessing section\n",
    "num_groups = len(set(novel_names))\n",
    "doctopic_grouped = np.zeros((num_groups, num_topics))\n",
    "for i, name in enumerate(sorted(set(novel_names))):\n",
    "    doctopic_grouped[i, :] = np.mean(doctopic[novel_names == name, :], axis=0)\n",
    "\n",
    "doctopic = doctopic_grouped\n",
    "\n",
    "@suppress\n",
    "docnames = sorted(set(novel_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit into the space available, the table above displays the first 15\n",
    "of 20 topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the NMF fit\n",
    "\n",
    "The topics (or components) of the NMF fit preserve the distances between novels (see the figures below).\n",
    "\n",
    "Even though the NMF fit “discards” the fine-grained detail recorded in the\n",
    "matrix of word frequencies, the matrix factorization performed allows us to\n",
    "reconstruct the salient details of the underlying matrix.\n",
    "\n",
    "As we did in the previous section, let us identify the most significant topics\n",
    "for each text in the corpus.  This procedure does not differ in essence from the\n",
    "procedure for identifying the most frequent words in each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'novel_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-71e601a3630e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnovels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnovel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top NMF topics in...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoctopic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtop_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoctopic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtop_topics_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'novel_names' is not defined"
     ]
    }
   ],
   "source": [
    "novels = sorted(set(novel_names))\n",
    "print(\"Top NMF topics in...\")\n",
    "for i in range(len(doctopic)):\n",
    "    top_topics = np.argsort(doctopic[i,:])[::-1][0:3]\n",
    "    top_topics_str = ' '.join(str(t) for t in top_topics)\n",
    "    print(\"{}: {}\".format(novels[i], top_topics_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we already have lists of words (`topic_words`) most strongly associated\n",
    "with the components. For reference, we will display them again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# show the top 15 words\n",
    "for t in range(len(topic_words)):\n",
    "    print(\"Topic {}: {}\".format(t, ' '.join(topic_words[t][:15])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to inspect and to visualize topic models. Some of the most\n",
    "common methods are covered in [Visualizing topic models](topic_model_visualization.html#topic-model-visualization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinctive topics\n",
    "\n",
    "Consider the task of finding the topics that are distinctive of Austen using the\n",
    "NMF “topics”. Using the simple difference-in-averages we can find topics that to\n",
    "be associated with Austen’s novels rather than Brontë’s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'novel_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9aac4f8150b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mausten_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbronte_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnovel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"Austen\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mausten_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m\"CBronte\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'novel_names' is not defined"
     ]
    }
   ],
   "source": [
    "austen_indices, cbronte_indices = [], []\n",
    "for index, fn in enumerate(sorted(set(novel_names))):\n",
    "    if \"Austen\" in fn:\n",
    "        austen_indices.append(index)\n",
    "    elif \"CBronte\" in fn:\n",
    "        cbronte_indices.append(index)\n",
    "\n",
    "austen_avg = np.mean(doctopic[austen_indices, :], axis=0)\n",
    "cbronte_avg = np.mean(doctopic[cbronte_indices, :], axis=0)\n",
    "keyness = np.abs(austen_avg - cbronte_avg)\n",
    "ranking = np.argsort(keyness)[::-1]  # from highest to lowest; [::-1] reverses order in Python sequences\n",
    "\n",
    "# distinctive topics:\n",
    "ranking[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a id=fn-nmf href=#fn-nmf-link><strong>[1]</strong></a> While there are significant differences between NMF and LDA, there\n",
    "are also similarities. Indeed, if the texts in a corpus have certain\n",
    "properties, NMF and LDA will arrive at the same representation of a corpus\n",
    "[[AGH+13]](references.html#arora-practical-2013)."
   ]
  }
 ],
 "metadata": {
  "date": 1577189966.016678,
  "download_nb": true,
  "download_nb_path": null,
  "filename": "topic_model_python.rst",
  "filename_with_path": "topic_model_python",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "title": "Topic modeling in Python"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
